{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_mnist_99.4%.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPNWxFl89kvJEBu9nyRzbG0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avQvUhnvkn2f"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "#importing tensorflow\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten,BatchNormalization,MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import random as rn\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hly2qES4kw6q",
        "outputId": "d0b35bc6-79f6-4cc5-ac57-acc672623b5b"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoPqiXOXk5O6"
      },
      "source": [
        "X = X_train\n",
        "y = y_train\n",
        "\n",
        "test_x = X_test\n",
        "\n",
        "X = X / 255.0\n",
        "test_x = test_x / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9g_6m8QlDJt"
      },
      "source": [
        "X = X.reshape(-1,28,28,1)\n",
        "test_x = test_x.reshape(-1,28,28,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY4zF79hlEBV",
        "outputId": "64a8e5f0-d7d7-4f66-c95c-f33a5a82e1e4"
      },
      "source": [
        "y = to_categorical(y)\n",
        "\n",
        "print(f\"Label size {y.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label size (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhbDdjhVlH-R"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2qpB8RLlL3r"
      },
      "source": [
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EzxXKQDlQ0_"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.2, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "\n",
        "train_gen = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "test_gen = datagen.flow(X_test, y_test, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kImlbJqHlT-v"
      },
      "source": [
        "import datetime\n",
        "!rm -rf ./logs/ \n",
        "#tf.reset_default_graph()\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI-lprTQlYMD"
      },
      "source": [
        "def scheduler(epoch):\n",
        "  if epoch >= 40 and epoch <50:\n",
        "    return 0.001\n",
        "  elif (epoch >= 60 and epoch <80):\n",
        "    return 0.001\n",
        "  \n",
        "  elif (epoch >= 81 and epoch <99):\n",
        "    return 0.001\n",
        "\n",
        "  else:\n",
        "    return 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcUuwevKlbGq"
      },
      "source": [
        "filepath=\"weights.hdf5\"\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "checkpoint_1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah3_j1P-leTc",
        "outputId": "27fe15b3-cee5-403f-f618-9a1e13c9f685"
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "   \n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "   \n",
        "\n",
        "model.add(Conv2D(8, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "   \n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(13, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\t\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 16)        4624      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 8)           1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 13)                1677      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                140       \n",
            "=================================================================\n",
            "Total params: 7,921\n",
            "Trainable params: 7,921\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ey1JljWlh8T"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(learning_rate=0.001),metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tvUHiXhlnVO",
        "outputId": "109a32cf-909a-4e4e-cafe-ea06b0c653e5"
      },
      "source": [
        "for i in range(50):\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,write_graph=True,histogram_freq=1)\n",
        "  callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "  history = model.fit(train_gen, \n",
        "                              epochs = 300,\n",
        "                              #use_multiprocessing=True, \n",
        "                              #workers=5,\n",
        "                              steps_per_epoch = X.shape[0] // batch_size,\n",
        "                              validation_data = test_gen,\n",
        "                              validation_steps = X_test.shape[0] // batch_size,\n",
        "                              callbacks = [tensorboard_callback,checkpoint_1]\n",
        "                              \n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "937/937 [==============================] - 47s 50ms/step - loss: 0.0497 - accuracy: 0.9850 - val_loss: 0.0459 - val_accuracy: 0.9861\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 47s 50ms/step - loss: 0.0478 - accuracy: 0.9851 - val_loss: 0.0504 - val_accuracy: 0.9842\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 47s 50ms/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.0519 - val_accuracy: 0.9842\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 47s 50ms/step - loss: 0.0451 - accuracy: 0.9857 - val_loss: 0.0532 - val_accuracy: 0.9845\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 47s 50ms/step - loss: 0.0469 - accuracy: 0.9854 - val_loss: 0.0572 - val_accuracy: 0.9852\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0461 - accuracy: 0.9861 - val_loss: 0.0502 - val_accuracy: 0.9845\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0468 - accuracy: 0.9851 - val_loss: 0.0520 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0469 - accuracy: 0.9856 - val_loss: 0.0510 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0455 - accuracy: 0.9860 - val_loss: 0.0478 - val_accuracy: 0.9839\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0472 - accuracy: 0.9851 - val_loss: 0.0422 - val_accuracy: 0.9869\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0464 - accuracy: 0.9855 - val_loss: 0.0494 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0452 - accuracy: 0.9866 - val_loss: 0.0511 - val_accuracy: 0.9862\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 49s 52ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 0.0514 - val_accuracy: 0.9854\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 53s 57ms/step - loss: 0.0482 - accuracy: 0.9847 - val_loss: 0.0489 - val_accuracy: 0.9852\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 52ms/step - loss: 0.0447 - accuracy: 0.9865 - val_loss: 0.0501 - val_accuracy: 0.9844\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0460 - accuracy: 0.9861 - val_loss: 0.0485 - val_accuracy: 0.9869\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0458 - accuracy: 0.9863 - val_loss: 0.0455 - val_accuracy: 0.9857\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 49s 52ms/step - loss: 0.0442 - accuracy: 0.9864 - val_loss: 0.0519 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 50s 53ms/step - loss: 0.0469 - accuracy: 0.9854 - val_loss: 0.0492 - val_accuracy: 0.9871\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 52ms/step - loss: 0.0466 - accuracy: 0.9854 - val_loss: 0.0498 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0477 - accuracy: 0.9850 - val_loss: 0.0556 - val_accuracy: 0.9849\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0457 - accuracy: 0.9858 - val_loss: 0.0423 - val_accuracy: 0.9849\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0457 - accuracy: 0.9859 - val_loss: 0.0530 - val_accuracy: 0.9835\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0459 - accuracy: 0.9854 - val_loss: 0.0449 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0462 - accuracy: 0.9862 - val_loss: 0.0474 - val_accuracy: 0.9856\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 49s 52ms/step - loss: 0.0442 - accuracy: 0.9859 - val_loss: 0.0536 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 52ms/step - loss: 0.0447 - accuracy: 0.9864 - val_loss: 0.0622 - val_accuracy: 0.9798\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 49s 52ms/step - loss: 0.0445 - accuracy: 0.9863 - val_loss: 0.0464 - val_accuracy: 0.9867\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 52ms/step - loss: 0.0438 - accuracy: 0.9865 - val_loss: 0.0511 - val_accuracy: 0.9857\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 52ms/step - loss: 0.0452 - accuracy: 0.9859 - val_loss: 0.0524 - val_accuracy: 0.9839\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 52ms/step - loss: 0.0437 - accuracy: 0.9865 - val_loss: 0.0522 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 49s 52ms/step - loss: 0.0438 - accuracy: 0.9862 - val_loss: 0.0543 - val_accuracy: 0.9842\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 49s 52ms/step - loss: 0.0431 - accuracy: 0.9863 - val_loss: 0.0558 - val_accuracy: 0.9854\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 49s 52ms/step - loss: 0.0443 - accuracy: 0.9858 - val_loss: 0.0488 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 49s 52ms/step - loss: 0.0425 - accuracy: 0.9871 - val_loss: 0.0513 - val_accuracy: 0.9857\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0426 - accuracy: 0.9869 - val_loss: 0.0421 - val_accuracy: 0.9864\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 51ms/step - loss: 0.0435 - accuracy: 0.9870 - val_loss: 0.0513 - val_accuracy: 0.9845\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 50s 53ms/step - loss: 0.0441 - accuracy: 0.9863 - val_loss: 0.0479 - val_accuracy: 0.9861\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 50s 53ms/step - loss: 0.0436 - accuracy: 0.9866 - val_loss: 0.0521 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 49s 52ms/step - loss: 0.0422 - accuracy: 0.9865 - val_loss: 0.0556 - val_accuracy: 0.9824\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 48s 52ms/step - loss: 0.0409 - accuracy: 0.9871 - val_loss: 0.0476 - val_accuracy: 0.9861\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 49s 52ms/step - loss: 0.0430 - accuracy: 0.9873 - val_loss: 0.0570 - val_accuracy: 0.9859\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 50s 53ms/step - loss: 0.0438 - accuracy: 0.9858 - val_loss: 0.0492 - val_accuracy: 0.9856\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 51s 54ms/step - loss: 0.0443 - accuracy: 0.9867 - val_loss: 0.0473 - val_accuracy: 0.9845\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 49s 52ms/step - loss: 0.0413 - accuracy: 0.9868 - val_loss: 0.0538 - val_accuracy: 0.9854\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 51s 54ms/step - loss: 0.0432 - accuracy: 0.9866 - val_loss: 0.0539 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 51s 54ms/step - loss: 0.0440 - accuracy: 0.9868 - val_loss: 0.0453 - val_accuracy: 0.9862\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 51s 54ms/step - loss: 0.0430 - accuracy: 0.9870 - val_loss: 0.0473 - val_accuracy: 0.9844\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 51s 54ms/step - loss: 0.0439 - accuracy: 0.9864 - val_loss: 0.0511 - val_accuracy: 0.9840\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n",
            "Epoch 1/300\n",
            "937/937 [==============================] - 51s 54ms/step - loss: 0.0426 - accuracy: 0.9869 - val_loss: 0.0457 - val_accuracy: 0.9867\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.98706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMseL7vtlwkh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
